"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - éªŒè¯æ‰€æœ‰ä¿®å¤
"""

import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer

print("="*60)
print("Quick Test - Verifying All Fixes")
print("="*60)

# æµ‹è¯•1: åŸºæœ¬åŠ è½½å’Œpatch
print("\n[Test 1] Loading and patching model...")
try:
    from src.model_adapter import monkey_patch_model
    
    model = GPT2LMHeadModel.from_pretrained('gpt2')
    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
    tokenizer.pad_token = tokenizer.eos_token
    
    print("âœ“ Model loaded")
    
    model = monkey_patch_model(model, 'gpt2', injection_layers=[0])
    print("âœ“ Model patched successfully")
    
except Exception as e:
    print(f"âœ— Failed: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

# æµ‹è¯•2: åŸºæœ¬forward pass
print("\n[Test 2] Testing forward pass...")
try:
    text = "Hello world"
    inputs = tokenizer(text, return_tensors='pt')
    
    with torch.no_grad():
        outputs = model(**inputs)
    
    print(f"âœ“ Forward pass successful")
    print(f"  Output shape: {outputs.logits.shape}")
    
except Exception as e:
    print(f"âœ— Failed: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

# æµ‹è¯•3: æµ‹è¯•è¿”å›žå€¼
print("\n[Test 3] Testing return values...")
try:
    # ç›´æŽ¥è°ƒç”¨attention
    hidden_states = torch.randn(1, 2, 768)
    
    attn_output = model.transformer.h[0].attn(hidden_states)
    
    # æ£€æŸ¥è¿”å›žå€¼
    if isinstance(attn_output, tuple):
        print(f"âœ“ Attention returns tuple with {len(attn_output)} elements")
        print(f"  First element shape: {attn_output[0].shape}")
        if len(attn_output) > 1 and attn_output[1] is not None:
            print(f"  Second element (weights) shape: {attn_output[1].shape}")
    else:
        print(f"âœ“ Attention returns single tensor: {attn_output.shape}")
    
except Exception as e:
    print(f"âœ— Failed: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

# æµ‹è¯•4: æµ‹è¯•æ•°æ®åŠ è½½
# print("\n[Test 4] Testing data loading...")
# try:
#     from custom_datasets import prepare_dummy_data
    
#     dataloader = prepare_dummy_data(
#         tokenizer,
#         batch_size=2,
#         num_samples=5,
#         seq_length=32
#     )
    
#     batch = next(iter(dataloader))
#     print(f"âœ“ DataLoader works")
#     print(f"  Batch keys: {batch.keys()}")
#     print(f"  Input IDs shape: {batch['input_ids'].shape}")
    
# except Exception as e:
#     print(f"âœ— Failed: {e}")
#     import traceback
#     traceback.print_exc()
#     exit(1)

# æµ‹è¯•5: æµ‹è¯•collector
print("\n[Test 5] Testing IntermediateTensorCollector...")
try:
    from real_model_exp.src.experiment_runner import IntermediateTensorCollector, run_model_with_collection
    
    collector = IntermediateTensorCollector()
    
    # å‡†å¤‡è¾“å…¥
    inputs = tokenizer("Test", return_tensors='pt', padding='max_length', max_length=16)
    input_ids = inputs['input_ids']
    attention_mask = inputs.get('attention_mask')
    
    # è¿è¡Œcollection
    outputs, collected = run_model_with_collection(
        model, input_ids, attention_mask, collector, injection_config=None
    )
    
    print(f"âœ“ Collection successful")
    print(f"  Collected layers: {list(collected.keys())}")
    
    if len(collected) > 0:
        first_layer = list(collected.keys())[0]
        print(f"  Layer {first_layer} tensors: {list(collected[first_layer].keys())}")
    
except Exception as e:
    print(f"âœ— Failed: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

# æµ‹è¯•6: æµ‹è¯•æ³¨å…¥
print("\n[Test 6] Testing error injection...")
try:
    from src.fault_injection import InjectionConfig, InjectionLocation
    
    inj_config = InjectionConfig(
        location=InjectionLocation.SCORES,
        idx=(0, 0, 0, 0),
        bit=15,
        enabled=True
    )
    
    # è¿è¡Œå¸¦æ³¨å…¥çš„forward
    outputs, collected = run_model_with_collection(
        model, input_ids, attention_mask, collector, injection_config=inj_config
    )
    
    print(f"âœ“ Injection successful")
    
    # æ£€æŸ¥æ˜¯å¦çœŸçš„æ³¨å…¥äº†
    if len(collected) > 0:
        first_layer = list(collected.keys())[0]
        if 'injection_applied' in collected[first_layer]:
            print(f"  Injection applied: {collected[first_layer]['injection_applied']}")
    
except Exception as e:
    print(f"âœ— Failed: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

print("\n" + "="*60)
print("ðŸŽ‰ All tests passed!")
print("="*60)
print("\nYou can now run:")
print("  python full_example.py simple")